{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum likelihood estimation, naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the parameters of distributions\n",
    "\n",
    "We’re moving now from probability to statistics\n",
    "The basic question: given some data \n",
    "\n",
    "$x^{(1)},...,x^{(m)}$\n",
    "\n",
    "how do I find a distribution that \n",
    "captures this data “well”?\n",
    "\n",
    "In general (if we can pick from the space of all distributions), this is a hard question, \n",
    "but if we pick from a particular parameterized family of distributions $p(X,\\theta)$, the \n",
    "question is (at least a little bit) easier\n",
    "\n",
    "Question becomes: how do I find parameters $\\theta$ of this distribution that fit the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood estimation\n",
    "\n",
    "Given a distribution $p(X,\\theta)$, and a collection of observed (independent) data points \n",
    "$x^{(1)},...,x^{(m)}$, the probability of observing this data is simply\n",
    "\n",
    "$$p(x^{(1)},\\ldots,x^{(m)};\\theta) = \\prod_{i=1}^m p(x^{(i)};\\theta)$$\n",
    "\n",
    "Basic idea of maximum likelihood estimation (MLE): find the parameters that \n",
    "maximize the probability of the observed data\n",
    "maximize\n",
    "\n",
    "$$\n",
    "maximize_\\theta \\; \\prod_{i=1}^m p(x^{(i)};\\theta) = maximize_\\theta \\; \\frac{1}{m} \\sum_{i=1}^m \\log p(x^{(i)};\\theta)$$\n",
    "\n",
    "where $l_{\\theta}$ is called the log likelihood of the data\n",
    "Seems “obvious”, but there are many other ways of fitting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean (mu): 179.59999879116265\n",
      "Estimated standard deviation (sigma): 7.525952115737213\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "np.random.seed(100)\n",
    "data = np.random.normal(loc=5, scale=2, size=1000)  # mean=5, std=2\n",
    "\n",
    "data_new = [190, 172, 170, 182, 184]\n",
    "\n",
    "def neg_log_likelihood(params, data):\n",
    "    mu, sigma = params[0], params[1]\n",
    "    # Negative log likelihood for normal distribution\n",
    "    nll = -np.sum(stats.norm.logpdf(data, loc=mu, scale=sigma))\n",
    "    return nll\n",
    "\n",
    "initial_guess = [0, 1]  # initial step\n",
    "result = minimize(neg_log_likelihood, initial_guess, args=(data_new,), bounds=[(None, None), (1e-6, None)])  # sigma > 0\n",
    "\n",
    "mu_mle, sigma_mle = result.x\n",
    "print(f\"Estimated mean (mu): {mu_mle}\")\n",
    "print(f\"Estimated standard deviation (sigma): {sigma_mle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 75 points : 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = [[0, 0],\n",
    "    [0, 1],\n",
    "    [0, 2],\n",
    "    [2, 1],\n",
    "    [2, 0],\n",
    "    [1, 2],\n",
    "    [1, 0]]\n",
    " \n",
    "y = [1, 0, 1, 0, 1, 0, 1]\n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X, y).predict([[0, 2]])\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
