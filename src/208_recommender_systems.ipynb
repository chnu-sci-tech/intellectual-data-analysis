{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approaches to collaborative filtering\n",
    "\n",
    "**User â€“ user approaches**: find the users that are most similar to myself (based \n",
    "upon only those items that are rated for both of us), and predict scores for other \n",
    "items based upon the average \n",
    "\n",
    "**Item â€“ item approaches**: find the items most similar to a given item (based upon \n",
    "all users rated both items), and predict scores for other users based upon the \n",
    "average\n",
    "\n",
    "**Matrix factorization approaches**: find some low-rank decomposition of the ð‘‹\n",
    "matrix that agrees at observed values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-User Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-User Pearson Correlation Matrix:\n",
      "           0         1         2         3         4\n",
      "0  1.000000  0.774291 -0.186441 -0.178683 -0.978839\n",
      "1  0.774291  1.000000  0.019854  0.162791 -0.628768\n",
      "2 -0.186441  0.019854  1.000000  0.972828  0.221028\n",
      "3 -0.178683  0.162791  0.972828  1.000000  0.258904\n",
      "4 -0.978839 -0.628768  0.221028  0.258904  1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example user-item matrix with ratings\n",
    "ratings_matrix = np.array([\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 0, 1],\n",
    "    [1, 1, 0, 5],\n",
    "    [1, 0, 0, 4],\n",
    "    [0, 1, 5, 4],\n",
    "])\n",
    "\n",
    "# Convert the matrix to a DataFrame for easier handling\n",
    "ratings_df = pd.DataFrame(ratings_matrix, columns=[\"Item1\", \"Item2\", \"Item3\", \"Item4\"])\n",
    "\n",
    "user_similarity = ratings_df.T.corr(method='pearson')\n",
    "\n",
    "print(\"User-User Pearson Correlation Matrix:\\n\", user_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0331985858244794\n"
     ]
    }
   ],
   "source": [
    "# Predict function to compute weighted ratings\n",
    "def predict_rating(user_index, item_index, ratings_df, similarity_matrix):\n",
    "    user_means = ratings_df.replace(0, np.nan).mean(axis=1).values\n",
    "\n",
    "    # Get the ratings for the item from all other users\n",
    "    item_ratings = ratings_df.iloc[:, item_index]\n",
    "    \n",
    "    # Get the similarity of the target user with all other users\n",
    "    user_similarities = similarity_matrix[user_index]\n",
    "    \n",
    "    # Filter for only users who rated the item and exclude self-similarity\n",
    "    non_zero_indices = item_ratings[item_ratings > 0].index\n",
    "    similarities = user_similarities[non_zero_indices]\n",
    "    ratings = item_ratings[non_zero_indices]\n",
    "    means = user_means[non_zero_indices]\n",
    "    \n",
    "    # If no other user has rated this item, return 0 as prediction\n",
    "    if len(similarities) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Weighted sum of ratings and normalize by similarity sum\n",
    "    \n",
    "    ratings_weighted = ratings - means\n",
    "    weighted_sum = np.dot(similarities, ratings_weighted)\n",
    "    \n",
    "    sum_of_similarities = np.sum(np.abs(similarities))\n",
    "\n",
    "    predicted = weighted_sum / sum_of_similarities if sum_of_similarities != 0 else 0\n",
    "\n",
    "    return ratings.mean() + predicted\n",
    "\n",
    "print(predict_rating(4, 0, ratings_df, user_similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00063558 0.99936347]\n",
      " [1.99965977 1.00034074]\n",
      " [2.99965485 1.20034566]\n",
      " [3.9998681  1.0001321 ]\n",
      " [5.00009002 0.79990984]\n",
      " [6.00008587 0.999914  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=2, init='random', random_state=0)\n",
    "W = model.fit_transform(X)\n",
    "H = model.components_\n",
    "nR = np.dot(W,H)\n",
    "print(nR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
